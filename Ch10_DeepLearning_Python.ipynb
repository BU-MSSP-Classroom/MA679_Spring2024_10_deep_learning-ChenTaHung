{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc378879",
   "metadata": {},
   "source": [
    "# Class Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1c117",
   "metadata": {},
   "source": [
    "## In class activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b9c178",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib.pyplot import subplots\n",
    "#import statsmodels.api as sm\n",
    "from plotnine import *\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as sm\n",
    "#import ISLP as islp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8f84d",
   "metadata": {},
   "source": [
    "### Ames Housing data\n",
    "\n",
    "\n",
    "Please take a look at the Ames Hoursing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7792c845",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw=pd.read_csv(\"ames_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde9d19",
   "metadata": {},
   "source": [
    "Use data of `ames_raw` up to 2008 predict the housing price for the later years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb9eca2",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw_2009, ames_raw_2008= ames_raw.query('`Yr Sold`>=2008').copy(), ames_raw.query('`Yr Sold` <2008').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "421bcab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>1612</td>\n",
       "      <td>526352080</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10667</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>167300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>1613</td>\n",
       "      <td>526352090</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>10628</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>167000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>1614</td>\n",
       "      <td>526355170</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>95.0</td>\n",
       "      <td>13651</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>1615</td>\n",
       "      <td>526355190</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>95.0</td>\n",
       "      <td>15865</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>1616</td>\n",
       "      <td>527105140</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12394</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Family</td>\n",
       "      <td>225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>2926</td>\n",
       "      <td>923275080</td>\n",
       "      <td>80</td>\n",
       "      <td>RL</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>2927</td>\n",
       "      <td>923276100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8885</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>131000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>2928</td>\n",
       "      <td>923400125</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>2929</td>\n",
       "      <td>924100070</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10010</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>2930</td>\n",
       "      <td>924151050</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>188000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "1611   1612  526352080           20        RL          85.0     10667   Pave   \n",
       "1612   1613  526352090           20        RL          85.0     10628   Pave   \n",
       "1613   1614  526355170           20        RL          95.0     13651   Pave   \n",
       "1614   1615  526355190           20        RL          95.0     15865   Pave   \n",
       "1615   1616  527105140           60        RL           NaN     12394   Pave   \n",
       "...     ...        ...          ...       ...           ...       ...    ...   \n",
       "2925   2926  923275080           80        RL          37.0      7937   Pave   \n",
       "2926   2927  923276100           20        RL           NaN      8885   Pave   \n",
       "2927   2928  923400125           85        RL          62.0     10441   Pave   \n",
       "2928   2929  924100070           20        RL          77.0     10010   Pave   \n",
       "2929   2930  924151050           60        RL          74.0      9627   Pave   \n",
       "\n",
       "     Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "1611   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1612   NaN       Reg          Lvl  ...         0     NaN   GdWo          NaN   \n",
       "1613   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1614   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1615   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "...    ...       ...          ...  ...       ...     ...    ...          ...   \n",
       "2925   NaN       IR1          Lvl  ...         0     NaN  GdPrv          NaN   \n",
       "2926   NaN       IR1          Low  ...         0     NaN  MnPrv          NaN   \n",
       "2927   NaN       Reg          Lvl  ...         0     NaN  MnPrv         Shed   \n",
       "2928   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "2929   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "\n",
       "     Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "1611        0       3    2007       WD           Normal     167300  \n",
       "1612        0       4    2007       WD           Normal     167000  \n",
       "1613        0       2    2007       WD           Normal     244000  \n",
       "1614        0      10    2007       WD           Normal     268000  \n",
       "1615        0      10    2007       WD           Family     225000  \n",
       "...       ...     ...     ...       ...             ...        ...  \n",
       "2925        0       3    2006       WD           Normal     142500  \n",
       "2926        0       6    2006       WD           Normal     131000  \n",
       "2927      700       7    2006       WD           Normal     132000  \n",
       "2928        0       4    2006       WD           Normal     170000  \n",
       "2929        0      11    2006       WD           Normal     188000  \n",
       "\n",
       "[1319 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ames_raw_2008"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da715eb",
   "metadata": {},
   "source": [
    "Use the following loss function calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145b46d4",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_loss(prediction,actual):\n",
    "  difpred = actual-prediction\n",
    "  RMSE =pow(difpred.pow(2).mean(),1/2)\n",
    "  operation_loss=abs(sum(difpred[difpred<0]))+sum(0.1*actual[difpred>0])\n",
    "  return RMSE,operation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124297b",
   "metadata": {},
   "source": [
    "Use a simple neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "872999b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "class DataLoader:\n",
    "    def __init__(self, data, target, batch_size=32):\n",
    "        # Assume data and target are already tensors or numpy arrays\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.target = torch.tensor(target, dtype=torch.float32)\n",
    "        self.batch_size = batch_size\n",
    "        self.n_samples = self.data.size(0) # Assuming data is 2D (samples, features)\n",
    "        self.n_batches = math.ceil(self.n_samples / self.batch_size)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.current_batch = 0 # Reset counter each time iter is called\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_batch >= self.n_batches:\n",
    "            raise StopIteration\n",
    "        \n",
    "        start = self.current_batch * self.batch_size\n",
    "        end = start + self.batch_size\n",
    "        if end > self.n_samples:\n",
    "            end = self.n_samples\n",
    "            \n",
    "        self.current_batch += 1\n",
    "        return self.data[start:end], self.target[start:end]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b601a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = ames_raw_2008[['Lot Area', 'Overall Qual',\n",
    "       'Overall Cond', 'Year Built', 'Year Remod/Add', '1st Flr SF',\n",
    "       '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Full Bath',\n",
    "       'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'TotRms AbvGrd',\n",
    "       'Fireplaces', 'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch',\n",
    "       '3Ssn Porch', 'Screen Porch', 'Pool Area', 'Misc Val', 'Mo Sold',\n",
    "       'Yr Sold']]\n",
    "y_train = ames_raw_2008['SalePrice']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = ames_raw_2009[['Lot Area', 'Overall Qual',\n",
    "       'Overall Cond', 'Year Built', 'Year Remod/Add', '1st Flr SF',\n",
    "       '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Full Bath',\n",
    "       'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'TotRms AbvGrd',\n",
    "       'Fireplaces', 'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch',\n",
    "       '3Ssn Porch', 'Screen Porch', 'Pool Area', 'Misc Val', 'Mo Sold',\n",
    "       'Yr Sold']]\n",
    "y_test = ames_raw_2009['SalePrice']\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b138e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "amesloader = DataLoader(data = X_train_scaled, target = y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e27fe0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Class\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size = 4, output_size = 1):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.Linear1 = nn.Linear(input_size, hidden_size)  \n",
    "        # output of : matrix 1 x input_size * input_size x hidden_size = 1 x hidden_size\n",
    "        self.Linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.Linear1(x)\n",
    "        out = self.Linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "071cbc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of NeuralNetwork(\n",
      "  (Linear1): Linear(in_features=24, out_features=4, bias=True)\n",
      "  (Linear2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42);\n",
    "NN = NeuralNetwork(input_size = X_train.shape[1])\n",
    "print(NN.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d562f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss Function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer =  torch.optim.RMSprop(NN.parameters(), lr = 0.001)\n",
    "\n",
    "# set iteration\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ddff77e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 40096547596.0\n",
      "Epoch 2, Average Loss: 40103195258.0\n",
      "Epoch 3, Average Loss: 40474898871.0\n",
      "Epoch 4, Average Loss: 40390183595.0\n",
      "Epoch 5, Average Loss: 40407063357.0\n",
      "Epoch 6, Average Loss: 40284007473.0\n",
      "Epoch 7, Average Loss: 40592889076.0\n",
      "Epoch 8, Average Loss: 40521839567.0\n",
      "Epoch 9, Average Loss: 40693621419.0\n",
      "Epoch 10, Average Loss: 41117058974.0\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in amesloader:\n",
    "               \n",
    "        # Forward pass\n",
    "        outputs = NN(X_batch)\n",
    "        # Compute Loss\n",
    "        loss = loss_function(outputs, y_batch.view(-1, 1))\n",
    "        #prediction = NN(X_batch)\n",
    "        pred = outputs.data\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(amesloader)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {round(avg_loss,0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90018571",
   "metadata": {},
   "source": [
    "When you decide on your model use the following to come up with your test loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "33e0e341",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE,echo=show_code",
    "kernel": "Python3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(194661.5156), tensor(28764556.))\n",
      "37894414336.0\n"
     ]
    }
   ],
   "source": [
    "NN.eval()  # set model to evaluation mode\n",
    "\n",
    "testloader = DataLoader(data = X_test_scaled, target = y_test.values,  batch_size = X_test.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, Y in testloader:\n",
    "\n",
    "        outputs = NN(X)\n",
    "        # get the predictions\n",
    "        predicted = outputs.squeeze()\n",
    "        predicted = predicted.data.numpy()\n",
    "        # update results\n",
    "        # print(Y.view(-1, 1).squeeze())\n",
    "    print(calc_loss(np.array(predicted), Y.view(-1, 1).squeeze()))\n",
    "    \n",
    "predictions_tensor = torch.tensor(predicted)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# If you're using a PyTorch loss function (like MSELoss for regression tasks):\n",
    "loss_function = torch.nn.MSELoss()\n",
    "loss = loss_function(predictions_tensor, y_test_tensor)\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45d1e7",
   "metadata": {},
   "source": [
    "Try to answer the following additional questions.\n",
    "\n",
    "- Does your model indicate a good fit?\n",
    "\n",
    "\n",
    "- How does your model result compare to the previous models you fit?\n",
    "\n",
    "\n",
    "- Can you explain what feature was important determinant of the price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb0ead",
   "metadata": {},
   "source": [
    "The loss that I got from the linear regression using the same features is:\n",
    "\n",
    "33892139.86634926\n",
    "\n",
    "Compare it with the loss of neural network, 28764556.0.\n",
    "\n",
    "\n",
    "The NN model greatly reduce the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf9dd0",
   "metadata": {},
   "source": [
    "### COVID 19 Survival in Mexico\n",
    "\n",
    "Let's revisit COVID-19 in Mexico dataset from the [Mexican government](https://datos.gob.mx/busca/dataset/informacion-referente-a-casos-covid-19-en-mexico).  This data is a version downloaded from [Kaggle](https://www.kaggle.com/datasets/meirnizri/covid19-dataset?resource=download).  The raw dataset consists of 21 unique features and 1,048,576 unique patients. In the Boolean features, 1 means \"yes\" and 2 means \"no\". values as 97 and 99 are missing data.\n",
    "\n",
    "- sex: 1 for female and 2 for male.\n",
    "- age: of the patient.\n",
    "- classification: COVID test findings. Values 1-3 mean that the patient was diagnosed with COVID in different degrees. 4 or higher means that the patient is not a carrier of COVID or that the test is inconclusive.\n",
    "- patient type: type of care the patient received in the unit. 1 for returned home and 2 for hospitalization.\n",
    "- pneumonia: whether the patient already have air sacs inflammation or not.\n",
    "- pregnancy: whether the patient is pregnant or not.\n",
    "- diabetes: whether the patient has diabetes or not.\n",
    "- copd: Indicates whether the patient has Chronic obstructive pulmonary disease or not.\n",
    "- asthma: whether the patient has asthma or not.\n",
    "- inmsupr: whether the patient is immunosuppressed or not.\n",
    "- hypertension: whether the patient has hypertension or not.\n",
    "- cardiovascular: whether the patient has heart or blood vessels related disease.\n",
    "- renal chronic: whether the patient has chronic renal disease or not.\n",
    "- other disease: whether the patient has other disease or not.\n",
    "- obesity: whether the patient is obese or not.\n",
    "- tobacco: whether the patient is a tobacco user.\n",
    "- usmr: Indicates whether the patient treated medical units of the first, second or third level.\n",
    "- medical unit: type of institution of the National Health System that provided the care.\n",
    "- intubed: whether the patient was connected to the ventilator.\n",
    "- icu: Indicates whether the patient had been admitted to an Intensive Care Unit.\n",
    "- date died: If the patient died indicate the date of death, and 9999-99-99 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef41dc",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "Train_COVID= pd.read_csv('Train_COVID.zip',compression='zip')\n",
    "Test_COVID= pd.read_csv('Test_COVID.zip',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9846d1",
   "metadata": {},
   "source": [
    "- Fit a sequence model that predicts the number of cases a week a head.\n",
    "\n",
    "- Modify your model to make prediction for different gender.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2ddbc",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63065e78",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db356786",
   "metadata": {},
   "source": [
    "## Problem set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2c5a9",
   "metadata": {},
   "source": [
    "### Writing your own gradient decent\n",
    "\n",
    "Consider the simple function $R(\\beta) = sin(\\beta) + \\beta/10$.\n",
    "\n",
    "(a) Draw a graph of this function over the range $\\beta \\in [−6, 6]$.\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683d706",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788e2b3",
   "metadata": {},
   "source": [
    "(b) What is the derivative of this function?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6932c",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c379",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(c) Given $\\beta_0 = 2.3$, run gradient descent to find a local minimum of $R(\\beat)$ using a learning rate of $\\rho= 0.1$. Show each of $\\beta_0,\\beta_1,\\dots$ in your plot, as well as the final answer.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9f93f",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134f645",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(d) Repeat with $\\beta_0 = 1.4$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efea5a0",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b33b24",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73f6ae",
   "metadata": {},
   "source": [
    "### Default\n",
    "\n",
    "Fit a neural network to the Default data. Use a single hidden layer with 10 units, and dropout regularization. Have a look at Labs 10.9.1–10.9.2 for guidance. Compare the classification performance of your model with that of linear logistic regression.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5f15d9d3",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import ISLP\n",
    "default = ISLP.load_data('Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4ecae4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "default['student'] = default['student'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "default['default'] = default['default'].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "34a431de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "default    0\n",
       "student    0\n",
       "balance    0\n",
       "income     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(default.default.mean())\n",
    "\n",
    "default.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b17abc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "# Data Loader\n",
    "class defaultDataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        # Assume data and target are already tensors or numpy arrays\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.target = torch.tensor(target, dtype=torch.float32)\n",
    "        # self.batch_size = batch_size\n",
    "        self.n_samples = self.data.shape[0]\n",
    "        \n",
    "    # def __iter__(self):\n",
    "    #     self.current_batch = 0\n",
    "    #     return self\n",
    "    \n",
    "    # def __next__(self):\n",
    "    #     if self.current_batch >= math.ceil(self.n_samples / self.batch_size):\n",
    "    #         raise StopIteration\n",
    "        \n",
    "    #     start = self.current_batch * self.batch_size\n",
    "    #     end = start + self.batch_size\n",
    "    #     if end > self.n_samples:\n",
    "    #         end = self.n_samples\n",
    "            \n",
    "    #     self.current_batch += 1\n",
    "        # return self.data[start:end], self.target[start:end]\n",
    "\n",
    "    def __len__(self) :\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]\n",
    "    \n",
    "# module class    \n",
    "class NeuralNetworkClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size = 4, output_size = 1):\n",
    "        super(NeuralNetworkClassifier, self).__init__()\n",
    "        self.Linear1 = nn.Linear(input_size, output_size)\n",
    "        # self.Linear2 = nn.Linear(hidden_size, output_size)\n",
    "        # self.Relu = nn.ReLU()\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.Linear1(x)\n",
    "        out = self.Sigmoid(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "9002b880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(default[['student', 'balance', 'income']], default['default'], test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "59b82774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of NeuralNetworkClassifier(\n",
      "  (Linear1): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (Sigmoid): Sigmoid()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "defTrain = defaultDataset(data =X_train_scaled, target = y_train.values)\n",
    "trainLoader = DataLoader(defTrain, batch_size = 200)\n",
    "# straitifiedDefLoader = StratifiedBatchLoader(data = X_train_scaled, target = y_train.values, batch_size = 200)\n",
    "\n",
    "NNclf  = NeuralNetworkClassifier(input_size = X_train_scaled.shape[1],  hidden_size=4, output_size=1)\n",
    "print(NNclf.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f72e2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss Function\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "# Set the optimzer as Stochastic Gradient Descent with a learning rate of 0.01\n",
    "optimizer = torch.optim.SGD(NNclf.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c206987",
   "metadata": {},
   "source": [
    "Numerical Stability in Loss Function: The Binary Cross Entropy (BCE) loss can suffer from numerical instability when the predicted probabilities are very close to 0 or 1. PyTorch provides BCEWithLogitsLoss, which combines a Sigmoid layer and the BCELoss in one single class. This is more numerically stable than using a plain Sigmoid followed by a BCELoss. Since your model ends with a Sigmoid activation, consider removing this last Sigmoid and using BCEWithLogitsLoss instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d448e02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  loss: 0.86541  accuracy: 0.05850\n",
      "epoch 1  loss: 0.75372  accuracy: 0.18762\n",
      "epoch 2  loss: 0.66189  accuracy: 0.49512\n",
      "epoch 3  loss: 0.58651  accuracy: 0.80588\n",
      "epoch 4  loss: 0.52452  accuracy: 0.95388\n",
      "epoch 5  loss: 0.47330  accuracy: 0.96700\n",
      "epoch 6  loss: 0.43072  accuracy: 0.96700\n",
      "epoch 7  loss: 0.39507  accuracy: 0.96700\n",
      "epoch 8  loss: 0.36499  accuracy: 0.96700\n",
      "epoch 9  loss: 0.33941  accuracy: 0.96700\n"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "\n",
    "# Define empty list variables that store the losses and accuracies at each epoch\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for inputs, targets in trainLoader:\n",
    "        outputs = NNclf(inputs)\n",
    "        loss = loss_function(outputs, targets.view(-1,1))\n",
    "\n",
    "        predicted = (outputs > 0.5).float()  # Ensure outputs are converted to 0 or 1.\n",
    "        \n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets.view(-1,1)).int().sum().item()  # Correctly sum boolean comparisons.\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        # Apply gradient clipping before the optimizer step\n",
    "        torch.nn.utils.clip_grad_norm_(NNclf.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "    \n",
    "        # print(correct)\n",
    "        # print(total)\n",
    "\n",
    "    acc = correct / total\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(acc)\n",
    "    print(f\"epoch {epoch}  loss: {loss:.5f}  accuracy: {acc:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "f46615d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuarcy: 96 %\n"
     ]
    }
   ],
   "source": [
    "NN.eval()  # set model to evaluation mode\n",
    "default_test = defaultDataset(data = X_test_scaled, target = y_test.values)\n",
    "testloader = DataLoader(default_test,  batch_size = X_test.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        # calculate output by running through the network\n",
    "        outputs = NNclf(inputs)\n",
    "        # get the predictions\n",
    "        predicted = torch.round(outputs.data)\n",
    "        # update results\n",
    "        total += Y.size(0)\n",
    "        correct += (predicted == labels.view(-1,1)).sum().item()\n",
    "    print(f'Test set accuarcy: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb5727",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d06410",
   "metadata": {},
   "source": [
    "### IMDb\n",
    "\n",
    "Repeat the analysis of Lab 10.9.5 on the IMDb data using a similarly structured neural network. We used 16 hidden units at each of two hidden layers. Explore the effect of increasing this to 32 and 64 units per layer, with and without 30% dropout regularization.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d63690",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b61f2",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e719c",
   "metadata": {},
   "source": [
    "### NYSE\n",
    "\n",
    "Fit a lag-5 autoregressive model to the NYSE data, as described in the text and Lab 10.9.6. Refit the model with a 12-level factor representing the month. Does this factor improve the performance of the model?\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d537a6d2",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82790743",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79190c",
   "metadata": {},
   "source": [
    "### NYSE 2\n",
    "In Section 10.9.6, we showed how to fit a linear AR model to the\n",
    "NYSE data using the `LinearRegression()` function. However, we also\n",
    "mentioned that we can “flatten” the short sequences produced for\n",
    "the RNN model in order to fit a linear AR model. Use this latter\n",
    "approach to fit a linear AR model to the NYSE data. Compare the test\n",
    "R2 of this linear AR model to that of the linear AR model that we fit\n",
    "in the lab. What are the advantages/disadvantages of each approach?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b49f2e",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6f42d",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "Repeat the previous exercise, but now fit a nonlinear AR model by\n",
    "“flattening” the short sequences produced for the RNN model.\n",
    "\n",
    " Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0a120",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5e731",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018aaf64",
   "metadata": {},
   "source": [
    "### NYSE 3\n",
    "\n",
    "Consider the RNN fit to the NYSE data in Section 10.9.6. Modify the code to allow inclusion of the variable day_of_week, and fit the RNN. Compute the test $R^2$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d3d82",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce0591",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d647a4b",
   "metadata": {},
   "source": [
    "### CNN on photo\n",
    "\n",
    "From your collection of personal photographs, pick 10 images of animals\n",
    "(such as dogs, cats, birds, farm animals, etc.). If the subject\n",
    "does not occupy a reasonable part of the image, then crop the image.\n",
    "Now use a pretrained image classification CNN as in Lab 10.9.4 to\n",
    "predict the class of each of your images, and report the probabilities\n",
    "for the top five predicted classes for each image.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c81612",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d56a27",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "Rmd_chunk_options": {
   "author": "Your Name",
   "date": "2022-12-21",
   "output": "github_document",
   "title": "Deep Learning"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "",
     ""
    ],
    [
     "css",
     "css",
     "",
     ""
    ],
    [
     "Python3",
     "ir",
     "",
     ""
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
